{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Theano do not support Python 3.5 on Windows. Use Python 2.7 or 3.4.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0872a2a3b81f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparse2Corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLdaModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\"\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarization\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\gensim\\corpora\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mucicorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUciCorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmalletcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMalletCorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msharded_corpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mShardedCorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\gensim\\corpora\\sharded_corpus.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0m_default_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0m_default_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\theano\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     raise RuntimeError(\n\u001b[1;32m---> 36\u001b[1;33m         \"Theano do not support Python 3.5 on Windows. Use Python 2.7 or 3.4.\")\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mtheano_logger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"theano\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Theano do not support Python 3.5 on Windows. Use Python 2.7 or 3.4."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "GA Data Science Q2 2016\n",
    "\n",
    "Code walk-through 13: Natural language processing\n",
    "\n",
    "* Pre-processing using spaCy\n",
    "* Bag-of-words and random forests\n",
    "* LDA using gensim\n",
    "* word2vec using gensim\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import cross_validation as cv, feature_extraction as fe, ensemble\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.models import LdaModel, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H2020_URL = 'http://cordis.europa.eu/data/cordis-h2020projects.csv'\n",
    "\n",
    "'''\n",
    "Pre-processing using spaCy\n",
    "'''\n",
    "\n",
    "# Initialise spaCy\n",
    "en = English()\n",
    "\n",
    "# Parse example sentence\n",
    "parsed = en('The serpentine syntax of legal language is often used to' +\n",
    "            ' obfuscate meaning and confuse those outside the law.')\n",
    "\n",
    "# Extract information\n",
    "# each word is analyses in the context of the sentence itself\n",
    "# dep is the dependency structure of the word\n",
    "# lemma is the root of the word\n",
    "# head - tree representaion of the language, finding the parent of word e.g. legal language; legal -> language\n",
    "for word in parsed:\n",
    "    print(\"{:15}{:15}{:15}{:15}{:15}\".format(word.text, word.pos_, word.dep_, \\\n",
    "                                             word.lemma_, word.head.lemma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Bag-of-words and random forests\n",
    "'''\n",
    "\n",
    "# Read in the H2020 dataset\n",
    "h2020 = pd.read_csv(H2020_URL, sep=';')\n",
    "\n",
    "# Convert 'totalCost' and 'ecMaxContribution' to numeric\n",
    "h2020['totalCost'] = pd.to_numeric(h2020.totalCost.map(lambda x: x.replace(',', '.')))\n",
    "h2020['ecMaxContribution'] = pd.to_numeric(h2020.ecMaxContribution.map(lambda x: x.replace(',', '.')))\n",
    "\n",
    "# Keep only signed contracts\n",
    "h2020 = h2020[h2020.status == 'SIGNED']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new variable representing whether the project was fully funded by the\n",
    "# European Commission\n",
    "h2020['fully_funded'] = ~(h2020.ecMaxContribution < h2020.totalCost)\n",
    "\n",
    "# Count words and 2-grams (combinations of two words) in the 'objective',\n",
    "# keeping only those that occur at least 5 times\n",
    "# feature extraction; extrating features out of text\n",
    "# fe.text.ENGLISH_STOP_WORDS commonly used word which you can amend.\n",
    "# ngrams count words of combinations up to 2 and atleast 5 times in the dataset\n",
    "vectorizer = fe.text.CountVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data for use in scikit-learn\n",
    "X = vectorizer.fit_transform(h2020.objective)\n",
    "y = h2020.fully_funded.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Include total project cost and coordinator country (using the UK as reference)\n",
    "country_dummies = pd.get_dummies(h2020.coordinatorCountry).drop('UK', axis=1)\n",
    "X = hstack([X, np.asmatrix(h2020.totalCost).T, country_dummies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a random forest with 20 decision trees\n",
    "rf1 = ensemble.RandomForestClassifier(n_estimators=20)\n",
    "rf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define stratified folds for cross-validation\n",
    "kf = cv.StratifiedKFold(y, n_folds=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute average AUC across folds\n",
    "aucs = cv.cross_val_score(rf1, X, y, scoring='roc_auc', cv=kf)\n",
    "np.mean(aucs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract variable importances and sort in descending order\n",
    "importances = pd.DataFrame({\n",
    "    'variable': vectorizer.get_feature_names() + ['totalCost'] + list(country_dummies.columns),\n",
    "    'importance': rf1.feature_importances_\n",
    "})\n",
    "importances.sort_values('importance', ascending=False, inplace=True)\n",
    "importances.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute tf–idf\n",
    "# (alternatively use `TfidfTransformer` on the output of `CountVectorizer`)\n",
    "vectorizer = fe.text.TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "# Prepare the data for use in scikit-learn\n",
    "X_tfidf = vectorizer.fit_transform(h2020.objective)\n",
    "\n",
    "# Include total project cost and coordinator country\n",
    "X_tfidf = hstack([X_tfidf, np.asmatrix(h2020.totalCost).T, country_dummies])\n",
    "\n",
    "# Train a random forest with 20 decision trees\n",
    "rf2 = ensemble.RandomForestClassifier(n_estimators=20)\n",
    "rf2.fit(X_tfidf, y)\n",
    "\n",
    "# Compute average AUC across folds\n",
    "aucs = cv.cross_val_score(rf2, X_tfidf, y, scoring='roc_auc', cv=kf)\n",
    "np.mean(aucs)\n",
    "\n",
    "# Extract variable importances and sort in descending order\n",
    "importances = pd.DataFrame({\n",
    "    'variable': vectorizer.get_feature_names() + ['totalCost'] + list(country_dummies.columns),\n",
    "    'importance': rf2.feature_importances_\n",
    "})\n",
    "importances.sort_values('importance', ascending=False, inplace=True)\n",
    "importances.head(10)\n",
    "\n",
    "'''\n",
    "LDA using gensim\n",
    "'''\n",
    "\n",
    "# Count words in the 'objective', keeping only those that occur at least 5 times\n",
    "vectorizer = fe.text.CountVectorizer(\n",
    "    stop_words='english',\n",
    "    min_df=5\n",
    ")\n",
    "X = vectorizer.fit_transform(h2020.objective)\n",
    "\n",
    "# Convert to gensim format\n",
    "corpus = Sparse2Corpus(X, documents_columns=False)\n",
    "\n",
    "# Create mapping from word IDs (integers) to words (strings); gensim requirement\n",
    "id2word = dict(enumerate(vectorizer.get_feature_names()))\n",
    "\n",
    "# Fit LDA model with 10 topics\n",
    "lda = LdaModel(corpus=corpus, num_topics=10, id2word=id2word)\n",
    "\n",
    "# Show top 5 words for each of the 10 topics; tuning is importan, if no of topids too high you could end up with overlap\n",
    "lda.show_topics(num_topics=10, num_words=5)\n",
    "\n",
    "'''\n",
    "word2vec using gensim\n",
    "'''\n",
    "\n",
    "# Convert adjectives and verbs to corresponding lemmas using spaCy\n",
    "objectives = [ \\\n",
    "    [ x.lemma_ if x.pos == spacy.parts_of_speech.ADJ or \\\n",
    "                  x.pos == spacy.parts_of_speech.VERB \\\n",
    "      else x.text \\\n",
    "      for x in en(text) ] \\\n",
    "    for text in h2020.objective ]\n",
    "\n",
    "# Fit word2vec model\n",
    "w2c = Word2Vec(sentences=objectives, size=100, window=5, min_count=5)\n",
    "\n",
    "# Which words are most similar to 'UK'?\n",
    "w2c.most_similar('UK')\n",
    "\n",
    "# Which words are most similar to 'UK' but not related to 'France'?\n",
    "w2c.most_similar(positive=['UK'], negative=['France'])\n",
    "\n",
    "# Which word doesn’t go with the others?\n",
    "w2c.doesnt_match(['Italy', 'Japan', 'France', 'UK'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

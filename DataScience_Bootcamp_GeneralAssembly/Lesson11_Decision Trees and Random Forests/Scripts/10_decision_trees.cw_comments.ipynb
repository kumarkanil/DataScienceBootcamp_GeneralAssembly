{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "GA Data Science Q2 2016\n",
    "\n",
    "Code walk-through 10: Decision trees and random forests\n",
    "\n",
    "* Decision trees\n",
    "* Random forests\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import cross_validation as cv, tree, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the Wine Quality datasets\n",
    "reds = pd.read_csv('../../Data/winequality_red.csv', sep=';')\n",
    "whites = pd.read_csv('../../Data/winequality_white.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a new indicator variable for the type of wine to predict the classes\n",
    "reds['red'] = 1\n",
    "whites['red'] = 0\n",
    "\n",
    "# Merge the two datasets, axis zero means it will concatenate by row\n",
    "wines = pd.concat([reds, whites], axis=0)\n",
    "\n",
    "# Because we are trying to binarise, this is why taking wwine quality we ask the question quality >= 8\n",
    "# Define a new indicator variable for ‘excellent’ wines (quality score ≥ 8)\n",
    "wines['excellent'] = wines.quality >= 8\n",
    "\n",
    "# Prepare the data for use in scikit-learn\n",
    "X = wines.drop(['quality', 'excellent'], axis=1)\n",
    "y = wines.excellent.astype('int') # turns true/false into zero and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Decision trees\n",
    "'''\n",
    "\n",
    "# Train a decision tree\n",
    "tree1 = tree.DecisionTreeClassifier()\n",
    "tree1.fit(X, y)\n",
    "\n",
    "# Export the tree for plotting\n",
    "tree.export_graphviz(tree1, 'tree1.dot', feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-18de1f249706>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-18de1f249706>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    dot -Tpng tree1.dot -o tree1.png\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dot -Tpng tree1.dot -o tree1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you have Graphviz (http://www.graphviz.org) installed, run:\n",
    "#     dot -Tpng tree1.dot -o tree1.png\n",
    "# Alternatively, use WebGraphviz at http://www.webgraphviz.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72930926282319475"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define stratified folds for cross-validation\n",
    "kf = cv.StratifiedKFold(y, n_folds=10, shuffle=True)\n",
    "\n",
    "# Compute average AUC across folds\n",
    "aucs = cv.cross_val_score(tree.DecisionTreeClassifier(),\\\n",
    "                          X, y, scoring='roc_auc', cv=kf)\n",
    "np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=50,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a decision tree by limiting:\n",
    "# * the maximum number of questions (depth)\n",
    "# * the minimum number of samples in each leaf\n",
    "tree2 = tree.DecisionTreeClassifier(max_depth=2, min_samples_leaf=50)\n",
    "tree2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export the tree for plotting\n",
    "# From seeing tree, value = non excellent is always hgher than excellent hence model predicts non excellent all the time\n",
    "tree.export_graphviz(tree2, 'tree2.dot', feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.08035384,  0.        ,  0.        ,  0.        ,\n",
       "        0.19338648,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.72625968,  0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate importances of predictors (the higher, the more important) Indicates how often the variable comes up in the tree\n",
    "# So we can see alcohol is the most influential\n",
    "tree2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fixed acidity', 0.0),\n",
       " ('volatile acidity', 0.080353840900456636),\n",
       " ('citric acid', 0.0),\n",
       " ('residual sugar', 0.0),\n",
       " ('chlorides', 0.0),\n",
       " ('free sulfur dioxide', 0.19338647782765769),\n",
       " ('total sulfur dioxide', 0.0),\n",
       " ('density', 0.0),\n",
       " ('pH', 0.0),\n",
       " ('sulphates', 0.0),\n",
       " ('alcohol', 0.72625968127188567),\n",
       " ('red', 0.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X.columns, tree2.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Random forests\n",
    "'''\n",
    "\n",
    "# Train a random forest with 20 decision trees, number of estimators is number of trees you want in the forest\n",
    "rf1 = ensemble.RandomForestClassifier(n_estimators=20)\n",
    "rf1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07532454,  0.10364619,  0.06905918,  0.09977061,  0.0821377 ,\n",
       "        0.09514271,  0.09613898,  0.09703323,  0.08646126,  0.09055142,\n",
       "        0.10403389,  0.0007003 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate importances of predictors (the higher, the more important)\n",
    "# how often it comes up in the 20 trees\n",
    "rf1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86199433234649947"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance through cross-validation\n",
    "aucs = cv.cross_val_score(ensemble.RandomForestClassifier(n_estimators=20),\\\n",
    "                          X, y, scoring='roc_auc', cv=kf)\n",
    "np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2 trees: mean AUC 72.17%\n",
      "  5 trees: mean AUC 79.31%\n",
      " 10 trees: mean AUC 82.11%\n",
      " 20 trees: mean AUC 85.20%\n",
      " 50 trees: mean AUC 89.02%\n",
      "100 trees: mean AUC 90.11%\n"
     ]
    }
   ],
   "source": [
    "# What happens when we increase the number of trees?\n",
    "for n_trees in [2, 5, 10, 20, 50, 100]:\n",
    "    aucs = cv.cross_val_score(\n",
    "        ensemble.RandomForestClassifier(n_estimators=n_trees), X, y,\\\n",
    "        scoring='roc_auc', cv=kf)\n",
    "    print('{:>3} trees: mean AUC {:.2%}'.format(n_trees, np.mean(aucs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
